---
title: Introdução ao DirectML
description: O Direct Machine Learning (DirectML) é uma API de nível baixo para o Machine Learning (ML).
ms.custom: Windows 10 May 2019 Update
ms.localizationpriority: high
ms.topic: article
ms.date: 04/19/2019
ms.openlocfilehash: 2dd37bc4c27364e26e4bbd4ae2cf5d43031c3314
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 09/16/2019
ms.locfileid: "74105124"
---
# <a name="introduction-to-directml"></a><span data-ttu-id="5010f-103">Introdução ao DirectML</span><span class="sxs-lookup"><span data-stu-id="5010f-103">Introduction to DirectML</span></span>

## <a name="summary"></a><span data-ttu-id="5010f-104">Resumo</span><span class="sxs-lookup"><span data-stu-id="5010f-104">Summary</span></span>

<span data-ttu-id="5010f-105">O Direct Machine Learning (DirectML) é uma API de nível baixo para o Machine Learning (ML).</span><span class="sxs-lookup"><span data-stu-id="5010f-105">Direct Machine Learning (DirectML) is a low-level API for machine learning (ML).</span></span> <span data-ttu-id="5010f-106">Os primitivos de aprendizado de máquina acelerados por hardware (chamados operadores) são os blocos de construção de DirectML.</span><span class="sxs-lookup"><span data-stu-id="5010f-106">Hardware-accelerated machine learning primitives (called operators) are the building blocks of DirectML.</span></span> <span data-ttu-id="5010f-107">A partir desses blocos de construção, você pode desenvolver técnicas de aprendizado de máquina como updimensioning, AntiAlias e transferência de estilo, para nomear, mas alguns.</span><span class="sxs-lookup"><span data-stu-id="5010f-107">From those building blocks, you can develop such machine learning techniques as upscaling, anti-aliasing, and style transfer, to name but a few.</span></span> <span data-ttu-id="5010f-108">Denoising e super resolução, por exemplo, permitem que você alcance efeitos raytraced impressionantes com menos raios por pixel.</span><span class="sxs-lookup"><span data-stu-id="5010f-108">Denoising and super-resolution, for example, allow you to achieve impressive raytraced effects with fewer rays per pixel.</span></span>

<span data-ttu-id="5010f-109">Você pode integrar cargas de trabalho com inferência a aprendizado de máquina em seu jogo, mecanismo, middleware, back-end ou outro aplicativo.</span><span class="sxs-lookup"><span data-stu-id="5010f-109">You can integrate machine learning inferencing workloads into your game, engine, middleware, backend, or other application.</span></span> <span data-ttu-id="5010f-110">O DirectML tem uma interface de programação e um fluxo de trabalho familiar (C++ nativo, nano-COM) DirectX 12-Style e tem suporte de todos os hardwares compatíveis com DirectX 12.</span><span class="sxs-lookup"><span data-stu-id="5010f-110">DirectML has a familiar (native C++, nano-COM) DirectX 12-style programming interface and workflow, and it's supported by all DirectX 12-compatible hardware.</span></span> <span data-ttu-id="5010f-111">Para aplicativos de exemplo do DirectML, incluindo um exemplo de um aplicativo de DirectML mínimo, consulte [aplicativos de exemplo DirectML](dml-min-app.md).</span><span class="sxs-lookup"><span data-stu-id="5010f-111">For DirectML sample applications, including a sample of a minimal DirectML application, see [DirectML sample applications](dml-min-app.md).</span></span>

<span data-ttu-id="5010f-112">O DirectML é introduzido no Windows 10, versão 1903 e na versão correspondente do SDK do Windows.</span><span class="sxs-lookup"><span data-stu-id="5010f-112">DirectML is introduced in Windows 10, version 1903, and in the corresponding version of the Windows SDK.</span></span>

## <a name="is-directml-appropriate-for-my-project"></a><span data-ttu-id="5010f-113">O DirectML é apropriado para meu projeto?</span><span class="sxs-lookup"><span data-stu-id="5010f-113">Is DirectML appropriate for my project?</span></span>

<span data-ttu-id="5010f-114">DirectML é um componente sob a proteção de [Machine Learning do Windows](/windows/ai) .</span><span class="sxs-lookup"><span data-stu-id="5010f-114">DirectML is a component under the [Windows Machine Learning](/windows/ai) umbrella.</span></span> <span data-ttu-id="5010f-115">A API WinML de nível superior é essencialmente focada em modelos, com seu fluxo de trabalho Load-BIND-Evaluate.</span><span class="sxs-lookup"><span data-stu-id="5010f-115">The higher-level WinML API is primarily model-focused, with its load-bind-evaluate workflow.</span></span> <span data-ttu-id="5010f-116">Mas domínios como jogos e mecanismos normalmente precisam de um nível mais baixo de abstração e um grau mais alto de controle de desenvolvedor, a fim de aproveitar ao máximo o silício.</span><span class="sxs-lookup"><span data-stu-id="5010f-116">But domains such as games and engines typically need a lower level of abstraction, and a higher degree of developer control, in order to take full advantage of the silicon.</span></span> <span data-ttu-id="5010f-117">Se você estiver contando milissegundos e apertando os horários dos quadros, o DirectML atenderá às suas necessidades de aprendizado de máquina.</span><span class="sxs-lookup"><span data-stu-id="5010f-117">If you're counting milliseconds, and squeezing frame times, then DirectML will meet your machine learning needs.</span></span>

<span data-ttu-id="5010f-118">Para cenários confiáveis em tempo real, de alto desempenho, baixa latência e/ou com restrição de recursos, use DirectML (em vez de WinML).</span><span class="sxs-lookup"><span data-stu-id="5010f-118">For reliable real-time, high-performance, low-latency, and/or resource-constrained scenarios, use DirectML (rather than WinML).</span></span> <span data-ttu-id="5010f-119">Você pode integrar o DirectML diretamente ao seu mecanismo existente ou ao pipeline de renderização.</span><span class="sxs-lookup"><span data-stu-id="5010f-119">You can integrate DirectML directly into your existing engine or rendering pipeline.</span></span> <span data-ttu-id="5010f-120">Ou, em um nível mais alto para estruturas e middleware de Machine Learning personalizados, o DirectML pode fornecer um back-end de alto desempenho no Windows.</span><span class="sxs-lookup"><span data-stu-id="5010f-120">Or, at a higher level for custom machine learning frameworks and middleware, DirectML can provide a high-performance backend on Windows.</span></span>

<span data-ttu-id="5010f-121">O WinML é implementado usando DirectML como um de seus back-ends.</span><span class="sxs-lookup"><span data-stu-id="5010f-121">WinML is itself implemented using DirectML as one of its backends.</span></span>

## <a name="what-work-does-directml-do-and-what-work-must-i-do-as-the-developer"></a><span data-ttu-id="5010f-122">O que o trabalho faz DirectML; e *o que o trabalho deve fazer* como desenvolvedor?</span><span class="sxs-lookup"><span data-stu-id="5010f-122">What work does DirectML do; and what work must *I* do as the developer?</span></span>

<span data-ttu-id="5010f-123">O DirectML executa com eficiência as camadas individuais do seu modelo de inferência na GPU (ou em núcleos de aceleração de ia, se presente).</span><span class="sxs-lookup"><span data-stu-id="5010f-123">DirectML efficiently executes the individual layers of your inference model on the GPU (or on AI-acceleration cores, if present).</span></span> <span data-ttu-id="5010f-124">Cada camada é um operador e o DirectML fornece uma biblioteca de operadores primitivos de aprendizado de máquina de baixo nível e aceleração de hardware.</span><span class="sxs-lookup"><span data-stu-id="5010f-124">Each layer is an operator, and DirectML provides you with a library of low-level, hardware-accelerated machine learning primitive operators.</span></span> <span data-ttu-id="5010f-125">Esses operadores têm otimizações específicas de hardware e de arquitetura projetadas para eles (mais sobre isso na seção [por que a DirectML tem um bom desempenho?](#why-does-directml-perform-so-well)).</span><span class="sxs-lookup"><span data-stu-id="5010f-125">These operators have hardware-specific and architecture-specific optimizations designed in to them (more on that in the section [Why does DirectML perform so well?](#why-does-directml-perform-so-well)).</span></span> <span data-ttu-id="5010f-126">Ao mesmo tempo, você, como desenvolvedor, vê uma interface única e independente de fornecedor para executar esses operadores.</span><span class="sxs-lookup"><span data-stu-id="5010f-126">At the same time, you as the developer see a single, vendor-agnostic interface for executing those operators.</span></span>

<span data-ttu-id="5010f-127">A biblioteca de operadores no DirectML fornece todas as operações comuns que você esperaria poder usar em uma carga de trabalho de Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="5010f-127">The library of operators in DirectML supplies all of the usual operations that you'd expect to be able to use in a machine learning workload.</span></span>

- <span data-ttu-id="5010f-128">Operadores de ativação, como **linear**, **ReLU**, **sigmoide**, **tanh** e muito mais.</span><span class="sxs-lookup"><span data-stu-id="5010f-128">Activation operators, such as **linear**, **ReLU**, **sigmoid**, **tanh**, and more.</span></span>
- <span data-ttu-id="5010f-129">Operadores com elemento, como **Add**, **exp**, **log**, **Max**, **min**, **sub** e muito mais.</span><span class="sxs-lookup"><span data-stu-id="5010f-129">Element-wise operators, such as **add**, **exp**, **log**, **max**, **min**, **sub**, and more.</span></span>
- <span data-ttu-id="5010f-130">Operadores de convolução, como **convolução** 2D e 3D e muito mais.</span><span class="sxs-lookup"><span data-stu-id="5010f-130">Convolution operators, such as 2D and 3D **convolution**, and more.</span></span>
- <span data-ttu-id="5010f-131">Operadores de redução, como **argmin**, **Average**, **L2**, **sum** e muito mais.</span><span class="sxs-lookup"><span data-stu-id="5010f-131">Reduction operators, such as **argmin**, **average**, **l2**, **sum**, and more.</span></span>
- <span data-ttu-id="5010f-132">Operadores de pooling, como **Average**, **LP** e **Max**.</span><span class="sxs-lookup"><span data-stu-id="5010f-132">Pooling operators, such as **average**, **lp**, and **max**.</span></span>
- <span data-ttu-id="5010f-133">Operadores de rede neural (NN), como **GEMM**, **Gru**, **lstm** e **RNN**.</span><span class="sxs-lookup"><span data-stu-id="5010f-133">Neural network (NN) operators, such as **gemm**, **gru**, **lstm**, and **rnn**.</span></span>
- <span data-ttu-id="5010f-134">E muito mais.</span><span class="sxs-lookup"><span data-stu-id="5010f-134">And many more.</span></span>

<span data-ttu-id="5010f-135">Para o desempenho máximo, e para que você não pague pelo que não usa, o DirectML coloca o controle em suas mãos como desenvolvedor sobre como a carga de trabalho do Machine Learning é executada no hardware.</span><span class="sxs-lookup"><span data-stu-id="5010f-135">For maximal performance, and so that you don't pay for what you don't use, DirectML puts the control into your hands as a developer over how your machine learning workload is executed on the hardware.</span></span> <span data-ttu-id="5010f-136">Descobrir quais operadores executar, e quando, é sua responsabilidade como desenvolvedor.</span><span class="sxs-lookup"><span data-stu-id="5010f-136">Figuring out which operators to execute, and when, is your responsibility as the developer.</span></span> <span data-ttu-id="5010f-137">As tarefas que são deixadas para seu critério incluem: transcrever o modelo; simplificando e otimizando suas camadas; carregando pesos; alocação de recursos, associação, gerenciamento de memória (assim como com o Direct3D 12); e a execução do grafo.</span><span class="sxs-lookup"><span data-stu-id="5010f-137">Tasks that are left to your discretion include: transcribing the model; simplifying and optimizing your layers; loading weights; resource allocation, binding, memory management (just as with Direct3D 12); and execution of the graph.</span></span>

<span data-ttu-id="5010f-138">Você mantém o conhecimento de alto nível de seus gráficos (você pode embutir seu código diretamente no seu modelo ou pode escrever seu próprio carregador de modelo).</span><span class="sxs-lookup"><span data-stu-id="5010f-138">You retain high-level knowledge of your graphs (you can hard-code your model directly, or you can write your own model loader).</span></span> <span data-ttu-id="5010f-139">Você pode criar um modelo de up-scaling, por exemplo, usando várias camadas de cada um dos operadores **upsample**, **convolução**, **normalização** e **ativação** .</span><span class="sxs-lookup"><span data-stu-id="5010f-139">You might design an upscaling model, for example, using several layers each of **upsample**, **convolution**, **normalization**, and **activation** operators.</span></span> <span data-ttu-id="5010f-140">Com essa familiaridade, o agendamento cuidadoso e o gerenciamento de barreira, você pode extrair o maior paralelismo e o desempenho do hardware.</span><span class="sxs-lookup"><span data-stu-id="5010f-140">With that familiarity, careful scheduling, and barrier management, you can extract the most parallelism and performance from the hardware.</span></span> <span data-ttu-id="5010f-141">Se você estiver desenvolvendo um jogo, o gerenciamento de recursos cuidadoso e o controle do agendamento permitirão que você intercalar as cargas de trabalho de aprendizado de máquina e a renderização tradicional para saturar a GPU.</span><span class="sxs-lookup"><span data-stu-id="5010f-141">If you're developing a game, then your careful resource management and control over scheduling enables you to interleave machine learning workloads and traditional rendering work in order to saturate the GPU.</span></span>

## <a name="whats-the-high-level-directml-workflow"></a><span data-ttu-id="5010f-142">O que é o fluxo de trabalho DirectML de alto nível?</span><span class="sxs-lookup"><span data-stu-id="5010f-142">What's the high-level DirectML workflow?</span></span>

<span data-ttu-id="5010f-143">Aqui está a receita de alto nível de como esperamos que DirectML seja usado.</span><span class="sxs-lookup"><span data-stu-id="5010f-143">Here's the high-level recipe for how we expect DirectML to be used.</span></span> <span data-ttu-id="5010f-144">Nas duas fases principais de inicialização e execução, você registra o trabalho em listas de comandos e, em seguida, executa-os em uma fila.</span><span class="sxs-lookup"><span data-stu-id="5010f-144">Within the two main phases of initialization and execution, you record work into command lists and then you execute them on a queue.</span></span>

### <a name="initialization"></a><span data-ttu-id="5010f-145">Inicialização</span><span class="sxs-lookup"><span data-stu-id="5010f-145">Initialization</span></span>

1. <span data-ttu-id="5010f-146">Crie seus recursos do Direct3D 12 &mdash; no dispositivo Direct3D 12, na fila de comandos, na lista de comandos e nos recursos como heaps de descritores.</span><span class="sxs-lookup"><span data-stu-id="5010f-146">Create your Direct3D 12 resources&mdash;the Direct3D 12 device, command queue, command list, and resources such as descriptor heaps.</span></span>
2. <span data-ttu-id="5010f-147">Como você está fazendo o Machine Learning inferência, bem como sua carga de trabalho de renderização, crie recursos &mdash; do DirectML o dispositivo DirectML e as instâncias de operador.</span><span class="sxs-lookup"><span data-stu-id="5010f-147">Since you're doing machine learning inferencing as well as your rendering workload, create DirectML resources&mdash;the DirectML device, and operator instances.</span></span> <span data-ttu-id="5010f-148">Se você tiver um modelo de aprendizado de máquina em que você precisa executar um tipo específico de convolução com um determinado tamanho de filtro tensor com um tipo de dados específico, esses serão todos os parâmetros no operador de **convolução** de DirectML.</span><span class="sxs-lookup"><span data-stu-id="5010f-148">If you have a machine learning model where you need to perform a particular type of convolution with a particular size of filter tensor with a particular data type, then those are all parameters into DirectML's **convolution** operator.</span></span>
3. <span data-ttu-id="5010f-149">Os registros DirectML funcionam nas listas de comandos do Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="5010f-149">DirectML records work into Direct3D 12 command lists.</span></span> <span data-ttu-id="5010f-150">Assim, quando a inicialização é feita, você registra a associação e a inicialização de (por exemplo) seu operador de convolução na sua lista de comandos.</span><span class="sxs-lookup"><span data-stu-id="5010f-150">So, once initialization is done, you record the binding and initialization of (for example) your convolution operator into your command list.</span></span> <span data-ttu-id="5010f-151">Em seguida, feche e execute a lista de comandos em sua fila como de costume.</span><span class="sxs-lookup"><span data-stu-id="5010f-151">Then, close and execute your command list on your queue as usual.</span></span>

### <a name="execution"></a><span data-ttu-id="5010f-152">Execução</span><span class="sxs-lookup"><span data-stu-id="5010f-152">Execution</span></span>

1. <span data-ttu-id="5010f-153">Carregue seus tempos de importância em recursos.</span><span class="sxs-lookup"><span data-stu-id="5010f-153">Upload your weight tensors into resources.</span></span> <span data-ttu-id="5010f-154">Um tensor no DirectML é representado usando um recurso regular do Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="5010f-154">A tensor in DirectML is represented using a regular Direct3D 12 resource.</span></span> <span data-ttu-id="5010f-155">Por exemplo, se você quiser carregar seus dados de peso para a GPU, faça isso da mesma maneira que faria com qualquer outro recurso do Direct3D 12 (use um heap de carregamento ou a fila de cópia).</span><span class="sxs-lookup"><span data-stu-id="5010f-155">For example, if you want to upload your weight data to the GPU, then you do that the same way you would with any other Direct3D 12 resource (use an upload heap, or the copy queue).</span></span>
2. <span data-ttu-id="5010f-156">Em seguida, você precisa associar esses recursos do Direct3D 12 como seus tempos de entrada e de saída.</span><span class="sxs-lookup"><span data-stu-id="5010f-156">Next, you need to bind those Direct3D 12 resources as your input and output tensors.</span></span> <span data-ttu-id="5010f-157">Registre-se em seu comando para listar a associação e a execução de seus operadores.</span><span class="sxs-lookup"><span data-stu-id="5010f-157">Record into your command list the binding and the execution of your operators.</span></span>
3. <span data-ttu-id="5010f-158">Feche e execute a lista de comandos.</span><span class="sxs-lookup"><span data-stu-id="5010f-158">Close and execute your command list.</span></span>

<span data-ttu-id="5010f-159">Assim como acontece com o Direct3D 12, o tempo de vida do recurso e a sincronização são de sua responsabilidade.</span><span class="sxs-lookup"><span data-stu-id="5010f-159">Just as with Direct3D 12, resource lifetime and synchronization are your responsibility.</span></span> <span data-ttu-id="5010f-160">Por exemplo, não libere seus objetos DirectML pelo menos até que eles concluam a execução na GPU.</span><span class="sxs-lookup"><span data-stu-id="5010f-160">For example, don't release your DirectML objects at least until they've completed execution on the GPU.</span></span>

## <a name="why-does-directml-perform-so-well"></a><span data-ttu-id="5010f-161">Por que o DirectML tem um bom desempenho?</span><span class="sxs-lookup"><span data-stu-id="5010f-161">Why does DirectML perform so well?</span></span>

<span data-ttu-id="5010f-162">Há um bom motivo pelo qual você não deve simplesmente escrever seu próprio operador de convolução (por exemplo,) como HLSL em um [sombreador de computação](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span><span class="sxs-lookup"><span data-stu-id="5010f-162">There's a good reason why you shouldn't just write your own convolution operator (for example) as HLSL in a [compute shader](/windows/desktop/direct3d12/pipelines-and-shaders-with-directx-12#direct3d-12-compute-pipeline).</span></span> <span data-ttu-id="5010f-163">A vantagem de usar o DirectML é que, &mdash; além de economizar o esforço de homebrewingr sua própria solução &mdash; , ele tem a capacidade de fornecer um desempenho muito melhor do que você poderia conseguir com um sombreador de computação de uso geral, escrito por mão, para algo como **convolução** ou **lstm**.</span><span class="sxs-lookup"><span data-stu-id="5010f-163">The advantage of using DirectML is that&mdash;apart from saving you the effort of homebrewing your own solution&mdash;it has the capability of giving you much better performance than you could achieve with a hand-written, general-purpose compute shader for something like **convolution**, or **lstm**.</span></span>

<span data-ttu-id="5010f-164">O DirectML consegue isso em parte devido ao recurso de metacomandos do Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="5010f-164">DirectML achieves this in part due to the Direct3D 12 metacommands feature.</span></span> <span data-ttu-id="5010f-165">Metacomandos expõem uma caixa preta de funcionalidade até DirectML, que permite aos fornecedores de hardware fornecer acesso DirectML a otimizações específicas de hardware e arquitetura específicas do fornecedor.</span><span class="sxs-lookup"><span data-stu-id="5010f-165">Metacommands expose a black box of functionality up to DirectML, which allows hardware vendors to provide DirectML access to vendor hardware-specific and architecture-specific optimizations.</span></span> <span data-ttu-id="5010f-166">Vários operadores &mdash; , por exemplo, a convolução seguida pela ativação &mdash; pode ser mesclada em um único metacomando. </span><span class="sxs-lookup"><span data-stu-id="5010f-166">Multiple operators&mdash;for example, convolution followed by activation&mdash;can be *fused* together into a single metacommand.</span></span> <span data-ttu-id="5010f-167">Devido a esses fatores, o DirectML tem a capacidade de exceder o desempenho de até mesmo um sombreador de computação com ajuste à mão escrito para ser executado em uma amplitude de hardware.</span><span class="sxs-lookup"><span data-stu-id="5010f-167">Because of these factors, DirectML has the capability to exceed the performance of even a very well-written hand-tuned compute shader written to run on a breadth of hardware.</span></span>

<span data-ttu-id="5010f-168">Metacomandos fazem parte da API do Direct3D 12, embora estejam acoplados livremente a ela.</span><span class="sxs-lookup"><span data-stu-id="5010f-168">Metacommands are part of the Direct3D 12 API, although they're loosely coupled to it.</span></span> <span data-ttu-id="5010f-169">Um metacomando é identificado por um [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid)fixo, enquanto quase tudo o mais a respeito (de seu comportamento e semântica à sua assinatura e nome) não é estritamente parte da API do Direct3D 12.</span><span class="sxs-lookup"><span data-stu-id="5010f-169">A metacommand is identified by a fixed [**GUID**](/windows/win32/api/guiddef/ns-guiddef-guid), while almost everything else about it (from its behavior and semantics to its signature and name) are not strictly part of the Direct3D 12 API.</span></span> <span data-ttu-id="5010f-170">Em vez disso, um metacomando é especificado entre seu autor e o driver que o implementa.</span><span class="sxs-lookup"><span data-stu-id="5010f-170">Rather, a metacommand is specified between its author and the driver that implements it.</span></span> <span data-ttu-id="5010f-171">Nesse caso, o autor é DirectML.</span><span class="sxs-lookup"><span data-stu-id="5010f-171">In this case, the author is DirectML.</span></span> <span data-ttu-id="5010f-172">Metacomandos são primitivos do Direct3D 12 (assim como desenha e despachado), para que possam ser registrados em uma lista de comandos e agendados para execução em conjunto.</span><span class="sxs-lookup"><span data-stu-id="5010f-172">Metacommands are Direct3D 12 primitives (just like Draws and Dispatches), so they can be recorded into a command list and scheduled for execution together.</span></span>

<span data-ttu-id="5010f-173">O DirectML acelera suas cargas de trabalho de aprendizado de máquina usando um conjunto inteiro de metacomandos do Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="5010f-173">DirectML accelerates your machine learning workloads using an entire suite of machine learning metacommands.</span></span> <span data-ttu-id="5010f-174">Consequentemente, você não precisa escrever caminhos de código específicos do fornecedor para obter aceleração de hardware para seu inferência.</span><span class="sxs-lookup"><span data-stu-id="5010f-174">Consequently, you don't need to write vendor-specific code paths to achieve hardware acceleration for your inferencing.</span></span> <span data-ttu-id="5010f-175">Se você for executar em um chip com aceleração de ia, o DirectML usará esse hardware para acelerar muito as operações, como a convolução.</span><span class="sxs-lookup"><span data-stu-id="5010f-175">If you happen to run on an AI-accelerated chip, then DirectML uses that hardware to greatly accelerate operations such as convolution.</span></span> <span data-ttu-id="5010f-176">Você pode usar o mesmo código que escreveu, sem modificá-lo, executá-lo em um chip que não seja de ia-acelerado (talvez a GPU integrada em seu laptop) e ainda obter grande aceleração de hardware de GPU.</span><span class="sxs-lookup"><span data-stu-id="5010f-176">You can take the same code that you wrote, without modifying it, run it on a chip that's not AI-accelerated (perhaps the integrated GPU in your laptop), and still get great GPU hardware acceleration.</span></span> <span data-ttu-id="5010f-177">E se nenhuma GPU estiver disponível, DirectML retornará à CPU.</span><span class="sxs-lookup"><span data-stu-id="5010f-177">And if no GPU is available, then DirectML falls back to the CPU.</span></span>
