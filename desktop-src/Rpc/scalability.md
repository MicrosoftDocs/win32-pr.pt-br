---
title: Escalabilidade
description: Escalabilidade
ms.assetid: 39327621-b536-4494-9319-9e9d4f534123
keywords:
- Escalabilidade
- RPC de chamada de procedimento remoto, práticas recomendadas, escalabilidade
ms.topic: article
ms.date: 05/31/2018
ms.openlocfilehash: 0728e35d9c9b27494014363c448be9965e39eea7
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: pt-BR
ms.lasthandoff: 09/16/2019
ms.locfileid: "103822928"
---
# <a name="scalability"></a><span data-ttu-id="0c66d-105">Escalabilidade</span><span class="sxs-lookup"><span data-stu-id="0c66d-105">Scalability</span></span>

<span data-ttu-id="0c66d-106">O termo, escalabilidade, geralmente é usado.</span><span class="sxs-lookup"><span data-stu-id="0c66d-106">The term, scalability, is often misused.</span></span> <span data-ttu-id="0c66d-107">Para esta seção, é fornecida uma definição dupla:</span><span class="sxs-lookup"><span data-stu-id="0c66d-107">For this section, a dual definition is provided:</span></span>

-   <span data-ttu-id="0c66d-108">A escalabilidade é a capacidade de utilizar totalmente a potência de processamento disponível em um sistema multiprocessador (2, 4, 8, 32 ou mais processadores).</span><span class="sxs-lookup"><span data-stu-id="0c66d-108">Scalability is the ability to fully utilize available processing power on a multiprocessor system (2, 4, 8, 32, or more processors).</span></span>
-   <span data-ttu-id="0c66d-109">A escalabilidade é a capacidade de atender a um grande número de clientes.</span><span class="sxs-lookup"><span data-stu-id="0c66d-109">Scalability is the ability to service a large number of clients.</span></span>

<span data-ttu-id="0c66d-110">Essas duas definições relacionadas são comumente conhecidas como *escalar verticalmente*.</span><span class="sxs-lookup"><span data-stu-id="0c66d-110">These two related definitions are commonly referred to as *scaling up*.</span></span> <span data-ttu-id="0c66d-111">O fim deste tópico fornece dicas sobre como *escalar* horizontalmente.</span><span class="sxs-lookup"><span data-stu-id="0c66d-111">The end of this topic provides tips about *scaling out*.</span></span>

<span data-ttu-id="0c66d-112">Essa discussão se concentra exclusivamente na gravação de servidores escalonáveis, não em clientes escalonáveis, pois os servidores escalonáveis são requisitos mais comuns.</span><span class="sxs-lookup"><span data-stu-id="0c66d-112">This discussion focuses exclusively on writing scalable servers, not scalable clients, because scalable servers are more common requirements.</span></span> <span data-ttu-id="0c66d-113">Esta seção também aborda a escalabilidade no contexto de servidores RPC e RPC.</span><span class="sxs-lookup"><span data-stu-id="0c66d-113">This section also addresses scalability in the context of RPC and RPC servers only.</span></span> <span data-ttu-id="0c66d-114">As práticas recomendadas para escalabilidade, como reduzir a contenção, evitar erros de cache frequentes em locais de memória global ou evitar o falso compartilhamento, não são discutidas aqui.</span><span class="sxs-lookup"><span data-stu-id="0c66d-114">Best practices for scalability, such as reducing contention, avoiding frequent cache misses on global memory locations, or avoiding false sharing, are not discussed here.</span></span>

## <a name="rpc-threading-model"></a><span data-ttu-id="0c66d-115">Modelo de Threading RPC</span><span class="sxs-lookup"><span data-stu-id="0c66d-115">RPC Threading Model</span></span>

<span data-ttu-id="0c66d-116">Quando uma chamada RPC é recebida por um servidor, a rotina de servidor (rotina do Gerenciador) é chamada em um thread fornecido pelo RPC.</span><span class="sxs-lookup"><span data-stu-id="0c66d-116">When an RPC call is received by a server, the server routine (manager routine) is called on a thread supplied by RPC.</span></span> <span data-ttu-id="0c66d-117">O RPC usa um pool de threads adaptável que aumenta e diminui à medida que a carga de trabalho flutua.</span><span class="sxs-lookup"><span data-stu-id="0c66d-117">RPC uses an adaptive thread pool that increases and decreases as workload fluctuates.</span></span> <span data-ttu-id="0c66d-118">A partir do Windows 2000, o núcleo do pool de threads RPC é uma porta de conclusão.</span><span class="sxs-lookup"><span data-stu-id="0c66d-118">Starting with Windows 2000, the core of the RPC thread pool is a completion port.</span></span> <span data-ttu-id="0c66d-119">A porta de conclusão e seu uso por RPC são ajustados de zero para rotinas de servidor de contenção baixa.</span><span class="sxs-lookup"><span data-stu-id="0c66d-119">The completion port and its usage by RPC are tuned for zero to low contention server routines.</span></span> <span data-ttu-id="0c66d-120">Isso significa que o pool de threads RPC aumenta agressivamente o número de threads de serviço se alguns se tornarem bloqueados.</span><span class="sxs-lookup"><span data-stu-id="0c66d-120">This means that the RPC thread pool aggressively increases the number of servicing threads if some become blocked.</span></span> <span data-ttu-id="0c66d-121">Ele opera na pré-continuação de que o bloqueio é raro e, se um thread é bloqueado, essa é uma condição temporária que é rapidamente resolvida.</span><span class="sxs-lookup"><span data-stu-id="0c66d-121">It operates on the presumption that blocking is rare, and if a thread gets blocked, this is a temporary condition that is quickly resolved.</span></span> <span data-ttu-id="0c66d-122">Essa abordagem permite a eficiência para servidores com baixa contenção.</span><span class="sxs-lookup"><span data-stu-id="0c66d-122">This approach enables efficiency for low contention servers.</span></span> <span data-ttu-id="0c66d-123">Por exemplo, um servidor RPC de chamada void operando em um servidor 550MHz de oito processadores acessado por uma SAN (rede de área do sistema) de alta velocidade serve mais de 30.000 chamadas void por segundo de mais de 200 clientes remotos.</span><span class="sxs-lookup"><span data-stu-id="0c66d-123">For example, a void call RPC server operating on an eight-processor 550MHz server accessed over a high speed system area network (SAN) serves over 30,000 void calls per second from over 200 remote clients.</span></span> <span data-ttu-id="0c66d-124">Isso representa mais de 108 milhões chamadas por hora.</span><span class="sxs-lookup"><span data-stu-id="0c66d-124">This represents more than 108 million calls per hour.</span></span>

<span data-ttu-id="0c66d-125">O resultado é que o pool de threads agressivos realmente fica no caminho quando a contenção no servidor é alta.</span><span class="sxs-lookup"><span data-stu-id="0c66d-125">The result is that the aggressive thread pool actually gets in the way when contention on the server is high.</span></span> <span data-ttu-id="0c66d-126">Para ilustrar, imagine um servidor de imposto pesado usado para acessar os arquivos remotamente.</span><span class="sxs-lookup"><span data-stu-id="0c66d-126">To illustrate, imagine a heavy-duty server used to remotely access files.</span></span> <span data-ttu-id="0c66d-127">Suponha que o servidor Adote a abordagem mais direta: ele simplesmente lê/grava o arquivo de forma síncrona no thread em que o RPC invoca a rotina do servidor.</span><span class="sxs-lookup"><span data-stu-id="0c66d-127">Assume the server adopts the most straightforward approach: it simply reads/writes the file synchronously on the thread on which that RPC invokes the server routine.</span></span> <span data-ttu-id="0c66d-128">Além disso, suponha que tenhamos um servidor de quatro processadores servindo muitos clientes.</span><span class="sxs-lookup"><span data-stu-id="0c66d-128">Also, assume we have a four-processor server serving many clients.</span></span>

<span data-ttu-id="0c66d-129">O servidor será iniciado com cinco threads (isso na verdade varia, mas cinco threads são usados para simplificar).</span><span class="sxs-lookup"><span data-stu-id="0c66d-129">The server will start with five threads (this actually varies, but five threads is used for simplicity).</span></span> <span data-ttu-id="0c66d-130">Depois que o RPC pega a primeira chamada RPC, ele despacha a chamada para a rotina do servidor e a rotina do servidor emite a e/s.</span><span class="sxs-lookup"><span data-stu-id="0c66d-130">Once RPC picks up the first RPC call, it dispatches the call to the server routine, and the server routine issues the I/O.</span></span> <span data-ttu-id="0c66d-131">Raramente, ele perde o cache de arquivos e, em seguida, bloqueia a espera pelo resultado.</span><span class="sxs-lookup"><span data-stu-id="0c66d-131">Infrequently, it misses the file cache and then blocks waiting for the result.</span></span> <span data-ttu-id="0c66d-132">Assim que ele é bloqueado, o quinto thread é liberado para pegar uma solicitação e um sexto thread é criado como uma espera ativa.</span><span class="sxs-lookup"><span data-stu-id="0c66d-132">As soon as it blocks, the fifth thread is released to pick up a request, and a sixth thread is created as a hot standby.</span></span> <span data-ttu-id="0c66d-133">Supondo que cada décimo de operação de e/s não seja o cache e bloqueará 100 milissegundos (um valor de tempo arbitrário) e supondo que o servidor de quatro processadores atenda a 20.000 chamadas por segundo (5.000 chamadas por processador), uma modelagem simplista prevê que cada processador gerará aproximadamente 50 threads.</span><span class="sxs-lookup"><span data-stu-id="0c66d-133">Assuming each tenth I/O operation misses the cache and will block for 100 milliseconds (an arbitrary time value), and assuming the four-processor server serves about 20,000 calls per second (5,000 calls per processor), a simplistic modeling would predict that each processor will spawn approximately 50 threads.</span></span> <span data-ttu-id="0c66d-134">Isso pressupõe que uma chamada que bloqueará a cada 2 milissegundos e depois de 100 milissegundos o primeiro thread seja liberado novamente, de modo que o pool se estabilizará em cerca de 200 threads (50 por processador).</span><span class="sxs-lookup"><span data-stu-id="0c66d-134">This assumes a call that will block comes every 2 milliseconds, and after 100 milliseconds the first thread is freed again so the pool will stabilize at about 200 threads (50 per processor).</span></span>

<span data-ttu-id="0c66d-135">O comportamento real é mais complicado, pois o grande número de threads causará opções de contexto extras que tornaram o servidor lento e também reduzirá a taxa de criação de novos threads, mas a ideia básica estará clara.</span><span class="sxs-lookup"><span data-stu-id="0c66d-135">The actual behavior is more complicated, as the high number of threads will cause extra context switches which slow the server, and also slow the rate of creation of new threads, but the basic idea is clear.</span></span> <span data-ttu-id="0c66d-136">O número de threads aumenta rapidamente à medida que os threads no servidor iniciam o bloqueio e aguardam algo (seja ele uma e/s ou acesso a um recurso).</span><span class="sxs-lookup"><span data-stu-id="0c66d-136">The number of threads goes up quickly as threads on the server start blocking and waiting for something (be it an I/O, or access to a resource).</span></span>

<span data-ttu-id="0c66d-137">O RPC e a porta de conclusão que solicita solicitações de entrada tentarão manter o número de threads RPC utilizáveis no servidor para ser igual ao número de processadores no computador.</span><span class="sxs-lookup"><span data-stu-id="0c66d-137">RPC and the completion port that gates incoming requests will try to maintain the number of usable RPC threads in the server to be equal to the number of processors on the machine.</span></span> <span data-ttu-id="0c66d-138">Isso significa que em um servidor de quatro processadores, uma vez que um thread retorna para RPC, se houver quatro ou mais threads de RPC utilizáveis, o quinto thread não terá permissão para pegar uma nova solicitação e, em vez disso, ficará em um estado de espera ativa no caso de um dos blocos de threads utilizáveis no momento.</span><span class="sxs-lookup"><span data-stu-id="0c66d-138">This means that on a four-processor server, once a thread returns to RPC, if there are four or more usable RPC threads, the fifth thread is not allowed to pick up a new request, and instead will sit in a hot standby state in case one of the currently usable threads blocks.</span></span> <span data-ttu-id="0c66d-139">Se o quinto thread aguardar tempo suficiente como uma espera ativa sem o número de threads de RPC utilizáveis cair abaixo do número de processadores, ele será liberado, ou seja, o pool de threads será reduzido.</span><span class="sxs-lookup"><span data-stu-id="0c66d-139">If the fifth thread waits long enough as a hot standby without the number of usable RPC threads dropping below the number of processors, it will be released, that is, the thread pool will decrease.</span></span>

<span data-ttu-id="0c66d-140">Imagine um servidor com vários threads.</span><span class="sxs-lookup"><span data-stu-id="0c66d-140">Imagine a server with many threads.</span></span> <span data-ttu-id="0c66d-141">Como explicado anteriormente, um servidor RPC termina com vários threads, mas somente se os threads forem bloqueados com frequência.</span><span class="sxs-lookup"><span data-stu-id="0c66d-141">As previously explained, an RPC server ends up with many threads, but only if the threads block often.</span></span> <span data-ttu-id="0c66d-142">Em um servidor em que os threads geralmente são bloqueados, um thread que retorna para o RPC é retirado da lista de espera ativa, porque todos os threads utilizáveis atualmente são bloqueados e recebem uma solicitação para processar.</span><span class="sxs-lookup"><span data-stu-id="0c66d-142">On a server where threads often block, a thread that returns to RPC is soon taken out of the hot standby list, because all currently usable threads block, and is given a request to process.</span></span> <span data-ttu-id="0c66d-143">Quando um thread é bloqueado, o Dispatcher do thread no kernel alterna o contexto para outro thread.</span><span class="sxs-lookup"><span data-stu-id="0c66d-143">When a thread blocks, the thread dispatcher in the kernel switches context to another thread.</span></span> <span data-ttu-id="0c66d-144">Esse contexto alterna por si só consome ciclos de CPU.</span><span class="sxs-lookup"><span data-stu-id="0c66d-144">This context switch by itself consumes CPU cycles.</span></span> <span data-ttu-id="0c66d-145">O próximo Thread executará código diferente, acessando diferentes estruturas de dados e terá uma pilha diferente, o que significa que a taxa de acesso ao cache de memória (os caches L1 e L2) será muito menor, resultando em uma execução mais lenta.</span><span class="sxs-lookup"><span data-stu-id="0c66d-145">The next thread will be executing different code, accessing different data structures, and will have a different stack, which means the memory cache hit rate (the L1 and L2 caches) will be much lower, resulting in slower execution.</span></span> <span data-ttu-id="0c66d-146">Os inúmeros threads que executam simultaneamente aumenta a contenção de recursos existentes, como heap, seções críticas no código do servidor e assim por diante.</span><span class="sxs-lookup"><span data-stu-id="0c66d-146">The numerous threads executing simultaneously increases contention for existing resources, such as heap, critical sections in the server code, and so on.</span></span> <span data-ttu-id="0c66d-147">Isso aumenta ainda mais a contenção como comboios no formulário de recursos.</span><span class="sxs-lookup"><span data-stu-id="0c66d-147">This further increases contention as convoys on resources form.</span></span> <span data-ttu-id="0c66d-148">Se a memória for baixa, a demanda de memória exercida pelo número grande e crescente de threads causará falhas de página, o que aumentará ainda mais a taxa na qual os threads são bloqueados e fará com que ainda mais threads sejam criados.</span><span class="sxs-lookup"><span data-stu-id="0c66d-148">If memory is low, the memory pressure exerted by the large and growing number of threads will cause page faults, which further increase the rate at which the threads block, and cause even more threads to be created.</span></span> <span data-ttu-id="0c66d-149">Dependendo da frequência com que ele é bloqueado e da quantidade de memória física disponível, o servidor pode se estabilizar em algum nível inferior de desempenho com uma taxa alta de alternância de contexto, ou pode deteriorar-se até o ponto em que ele está acessando apenas repetidamente o disco rígido e a alternância de contexto sem executar nenhum trabalho real.</span><span class="sxs-lookup"><span data-stu-id="0c66d-149">Depending on how often it blocks and how much physical memory is available, the server may either stabilize at some lower level of performance with a high context switch rate, or it may deteriorate to the point where it is only repeatedly accessing the hard disk and context switching without performing any actual work.</span></span> <span data-ttu-id="0c66d-150">Essa situação não será mostrada sob carga de trabalho leve, é claro, mas uma carga de trabalho pesada rapidamente traz o problema para a superfície.</span><span class="sxs-lookup"><span data-stu-id="0c66d-150">This situation will not show under light workload, of course, but a heavy workload quickly brings the problem to the surface.</span></span>

<span data-ttu-id="0c66d-151">Como isso pode ser impedido?</span><span class="sxs-lookup"><span data-stu-id="0c66d-151">How can this be prevented?</span></span> <span data-ttu-id="0c66d-152">Se os threads devem ser bloqueados, declare chamadas como assíncronas e, depois que a solicitação entrar na rotina do servidor, enfileirar-a para um pool de threads de trabalho que usam os recursos assíncronos do sistema de e/s e/ou RPC.</span><span class="sxs-lookup"><span data-stu-id="0c66d-152">If threads are expected to block, declare calls as asynchronous, and once the request enters the server routine, queue it to a pool of worker threads that use the asynchronous capabilities of the I/O system and/or RPC.</span></span> <span data-ttu-id="0c66d-153">Se o servidor estiver, por sua vez, fazendo com que as chamadas RPC tornem as assíncronas e certifique-se de que a fila não se expanda muito grande.</span><span class="sxs-lookup"><span data-stu-id="0c66d-153">If the server is in turn making RPC calls make those asynchronous, and make sure the queue does not grow too large.</span></span> <span data-ttu-id="0c66d-154">Se a rotina de servidor estiver executando a e/s de arquivo, use a e/s de arquivo assíncrono para enfileirar várias solicitações para o sistema de e/s e ter apenas alguns threads em fila e obter os resultados.</span><span class="sxs-lookup"><span data-stu-id="0c66d-154">If the server routine is performing file I/O, use asynchronous file I/O to queue multiple requests to the I/O system and have only a few threads queue them and pick up the results.</span></span> <span data-ttu-id="0c66d-155">Se a rotina de servidor estiver fazendo a e/s de rede, use os recursos assíncronos do sistema para emitir as solicitações e selecionar as respostas de forma assíncrona e usar o menor número possível de threads.</span><span class="sxs-lookup"><span data-stu-id="0c66d-155">If the server routine is doing network I/O, again, use the asynchronous capabilities of the system to issue the requests and pick up the replies asynchronously, and use as few threads as possible.</span></span> <span data-ttu-id="0c66d-156">Quando a e/s for concluída ou a chamada RPC que o servidor fez estiver concluída, conclua a chamada RPC assíncrona que forneceu a solicitação.</span><span class="sxs-lookup"><span data-stu-id="0c66d-156">When the I/O is done, or the RPC call the server made is complete, complete the asynchronous RPC call that delivered the request.</span></span> <span data-ttu-id="0c66d-157">Isso permitirá que o servidor seja executado com o mínimo de threads possível, o que aumenta o desempenho e o número de clientes que um servidor pode atender.</span><span class="sxs-lookup"><span data-stu-id="0c66d-157">This will enable the server to run with as few threads as possible, which increases the performance and the number of clients a server can service.</span></span>

## <a name="scale-out"></a><span data-ttu-id="0c66d-158">Escalonamento horizontal</span><span class="sxs-lookup"><span data-stu-id="0c66d-158">Scale Out</span></span>

<span data-ttu-id="0c66d-159">O RPC pode ser configurado para funcionar com o NLB (balanceamento de carga de rede) se o NLB estiver configurado de modo que todas as solicitações de um determinado endereço de cliente vá para o mesmo servidor.</span><span class="sxs-lookup"><span data-stu-id="0c66d-159">RPC can be configured to work with Network Load Balancing (NLB) if NLB is configured such that all requests from a given client address go to the same server.</span></span> <span data-ttu-id="0c66d-160">Como cada cliente RPC abre um pool de conexões (para obter mais informações, consulte [RPC e a rede](rpc-and-the-network.md)), é essencial que todas as conexões do pool do cliente em questão terminem no mesmo computador do servidor.</span><span class="sxs-lookup"><span data-stu-id="0c66d-160">Because each RPC client opens a connection pool (for more information, see [RPC and the Network](rpc-and-the-network.md)), it is essential that all connections from the pool of the given client end up on the same server computer.</span></span> <span data-ttu-id="0c66d-161">Desde que essa condição seja atendida, um cluster NLB pode ser configurado para funcionar como um servidor RPC grande com escalabilidade potencialmente excelente.</span><span class="sxs-lookup"><span data-stu-id="0c66d-161">As long as this condition is met, an NLB cluster can be configured to function as one large RPC server with potentially excellent scalability.</span></span>

 

 




